{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jpeg', 'jpg', 'bmp', 'png']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_exts = ['jpeg', 'jpg', 'bmp', 'png']\n",
    "img_exts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1000_F_72757953_CzkNyWKDinutYVOop5mYHyRSarV55ZM8.jpg',\n",
       " '110754-utyeqqosky-1547658396.jpeg',\n",
       " '2d5e8301-images_habits-of-happy-people-cr3.jpg',\n",
       " '35438_hd.jpg',\n",
       " '4344806.jpg',\n",
       " '835405.jpg',\n",
       " '95-Quotes-On-Being-Happy-With-Where-You-Are-in-Life-1000x600.jpg',\n",
       " 'advanced-english-vocabulary-happy.jpg',\n",
       " 'blog-2.jpeg',\n",
       " 'canva-happy-birthday-instagram-post-mFmsycgF9eM.jpg',\n",
       " 'e162ccda8ce0f197f8863f327add9233.jpg',\n",
       " 'GettyImages-871518740.jpg',\n",
       " 'GettyImages-Maskot.jpg',\n",
       " 'happiness2.jpg',\n",
       " 'happiness_thumbnail.jpg',\n",
       " 'happy-190806.jpg',\n",
       " 'happy-emoticon-giving-thumb-up-vector-6147510.jpg',\n",
       " 'happy-indians_5f66fd46d9f5b.jpg',\n",
       " 'happy-people-vector-839522.jpg',\n",
       " 'happy-person2.jpg',\n",
       " 'happy-smiley-face-balloons-against-colorful-cotton-royalty-free-image-1677446093.jpg',\n",
       " 'happy.jpg',\n",
       " 'happypeople-1024x679.jpg',\n",
       " 'How-to-Be-Happy_600x877-pinterest.jpg',\n",
       " 'If_You_Want_to_Be_Happy_Try_to_Make_Someone_Else_Happy.jpg',\n",
       " 'image24.jpeg',\n",
       " 'images100.jpg',\n",
       " 'images104.jpg',\n",
       " 'images106.jpg',\n",
       " 'images120.jpg',\n",
       " 'images124.jpg',\n",
       " 'images125.jpg',\n",
       " 'images129.jpg',\n",
       " 'images135.jpg',\n",
       " 'images153.jpg',\n",
       " 'images157.jpg',\n",
       " 'images16.jpg',\n",
       " 'images162.jpg',\n",
       " 'images165.jpg',\n",
       " 'images166.jpg',\n",
       " 'images178.jpg',\n",
       " 'images183.jpg',\n",
       " 'images19.jpg',\n",
       " 'images190.jpg',\n",
       " 'images192.jpg',\n",
       " 'images196.jpg',\n",
       " 'images20.jpg',\n",
       " 'images208.jpg',\n",
       " 'images217.jpg',\n",
       " 'images223.jpg',\n",
       " 'images228.jpg',\n",
       " 'images233.jpg',\n",
       " 'images235.jpg',\n",
       " 'images242.jpg',\n",
       " 'images251.jpg',\n",
       " 'images262.jpg',\n",
       " 'images269.jpg',\n",
       " 'images270.jpg',\n",
       " 'images273.jpg',\n",
       " 'images280.jpg',\n",
       " 'images282.jpg',\n",
       " 'images283.jpg',\n",
       " 'images286.jpg',\n",
       " 'images29.jpg',\n",
       " 'images290.jpg',\n",
       " 'images291.jpg',\n",
       " 'images298.jpg',\n",
       " 'images308.jpg',\n",
       " 'images314.jpg',\n",
       " 'images316.jpg',\n",
       " 'images318.jpg',\n",
       " 'images323.jpg',\n",
       " 'images336.jpg',\n",
       " 'images342.jpg',\n",
       " 'images355.jpg',\n",
       " 'images361.jpg',\n",
       " 'images400.jpg',\n",
       " 'images411.jpg',\n",
       " 'images412.jpg',\n",
       " 'images53.jpg',\n",
       " 'images6.jpg',\n",
       " 'images67.jpg',\n",
       " 'images70.jpg',\n",
       " 'images84.jpg',\n",
       " 'images87.jpg',\n",
       " 'images9.jpg',\n",
       " 'images93.jpg',\n",
       " 'images94.jpg',\n",
       " 'ipsos-global-advisor-happiness-2022-opti.jpg',\n",
       " 'istock-527028804.jpg',\n",
       " 'iStock_000015424718Small.jpg',\n",
       " 'ng-hands-up-carefree-enjoying-music-standing-against-white-wall_176420-38816.jpg',\n",
       " 'people-who-are-truly-happy.png',\n",
       " 'pexels_pixabay.jpg',\n",
       " 'shiny-happy-people.jpg',\n",
       " 'smile.woman_.jpg',\n",
       " 'smiley-1635449_1280.png',\n",
       " 'Successful-year.jpg',\n",
       " 'sunset-570881_1280.jpg',\n",
       " 'traitshappypeople.jpg',\n",
       " 'U3rmkCcX_400x400.jpg',\n",
       " 'v4-460px-Make-a-Person-Happy-Step-14.jpg',\n",
       " 'what-makes-people-happy1.jpg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(data_dir, 'happy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in img_exts:\n",
    "                print('image not in ext list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e: \n",
    "            print('issue with images {}'.format(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images\\happy\\1000_F_72757953_CzkNyWKDinutYVOop5mYHyRSarV55ZM8.jpg\n",
      "images\\happy\\110754-utyeqqosky-1547658396.jpeg\n",
      "images\\happy\\2d5e8301-images_habits-of-happy-people-cr3.jpg\n",
      "images\\happy\\35438_hd.jpg\n",
      "images\\happy\\4344806.jpg\n",
      "images\\happy\\835405.jpg\n",
      "images\\happy\\95-Quotes-On-Being-Happy-With-Where-You-Are-in-Life-1000x600.jpg\n",
      "images\\happy\\advanced-english-vocabulary-happy.jpg\n",
      "images\\happy\\blog-2.jpeg\n",
      "images\\happy\\canva-happy-birthday-instagram-post-mFmsycgF9eM.jpg\n",
      "images\\happy\\e162ccda8ce0f197f8863f327add9233.jpg\n",
      "images\\happy\\GettyImages-871518740.jpg\n",
      "images\\happy\\GettyImages-Maskot.jpg\n",
      "images\\happy\\happiness2.jpg\n",
      "images\\happy\\happiness_thumbnail.jpg\n",
      "images\\happy\\happy-190806.jpg\n",
      "images\\happy\\happy-emoticon-giving-thumb-up-vector-6147510.jpg\n",
      "images\\happy\\happy-indians_5f66fd46d9f5b.jpg\n",
      "images\\happy\\happy-people-vector-839522.jpg\n",
      "images\\happy\\happy-person2.jpg\n",
      "images\\happy\\happy-smiley-face-balloons-against-colorful-cotton-royalty-free-image-1677446093.jpg\n",
      "images\\happy\\happy.jpg\n",
      "images\\happy\\happypeople-1024x679.jpg\n",
      "images\\happy\\How-to-Be-Happy_600x877-pinterest.jpg\n",
      "images\\happy\\If_You_Want_to_Be_Happy_Try_to_Make_Someone_Else_Happy.jpg\n",
      "images\\happy\\image24.jpeg\n",
      "images\\happy\\images100.jpg\n",
      "images\\happy\\images104.jpg\n",
      "images\\happy\\images106.jpg\n",
      "images\\happy\\images120.jpg\n",
      "images\\happy\\images124.jpg\n",
      "images\\happy\\images125.jpg\n",
      "images\\happy\\images129.jpg\n",
      "images\\happy\\images135.jpg\n",
      "images\\happy\\images153.jpg\n",
      "images\\happy\\images157.jpg\n",
      "images\\happy\\images16.jpg\n",
      "images\\happy\\images162.jpg\n",
      "images\\happy\\images165.jpg\n",
      "images\\happy\\images166.jpg\n",
      "images\\happy\\images178.jpg\n",
      "images\\happy\\images183.jpg\n",
      "images\\happy\\images19.jpg\n",
      "images\\happy\\images190.jpg\n",
      "images\\happy\\images192.jpg\n",
      "images\\happy\\images196.jpg\n",
      "images\\happy\\images20.jpg\n",
      "images\\happy\\images208.jpg\n",
      "images\\happy\\images217.jpg\n",
      "images\\happy\\images223.jpg\n",
      "images\\happy\\images228.jpg\n",
      "images\\happy\\images233.jpg\n",
      "images\\happy\\images235.jpg\n",
      "images\\happy\\images242.jpg\n",
      "images\\happy\\images251.jpg\n",
      "images\\happy\\images262.jpg\n",
      "images\\happy\\images269.jpg\n",
      "images\\happy\\images270.jpg\n",
      "images\\happy\\images273.jpg\n",
      "images\\happy\\images280.jpg\n",
      "images\\happy\\images282.jpg\n",
      "images\\happy\\images283.jpg\n",
      "images\\happy\\images286.jpg\n",
      "images\\happy\\images29.jpg\n",
      "images\\happy\\images290.jpg\n",
      "images\\happy\\images291.jpg\n",
      "images\\happy\\images298.jpg\n",
      "images\\happy\\images308.jpg\n",
      "images\\happy\\images314.jpg\n",
      "images\\happy\\images316.jpg\n",
      "images\\happy\\images318.jpg\n",
      "images\\happy\\images323.jpg\n",
      "images\\happy\\images336.jpg\n",
      "images\\happy\\images342.jpg\n",
      "images\\happy\\images355.jpg\n",
      "images\\happy\\images361.jpg\n",
      "images\\happy\\images400.jpg\n",
      "images\\happy\\images411.jpg\n",
      "images\\happy\\images412.jpg\n",
      "images\\happy\\images53.jpg\n",
      "images\\happy\\images6.jpg\n",
      "images\\happy\\images67.jpg\n",
      "images\\happy\\images70.jpg\n",
      "images\\happy\\images84.jpg\n",
      "images\\happy\\images87.jpg\n",
      "images\\happy\\images9.jpg\n",
      "images\\happy\\images93.jpg\n",
      "images\\happy\\images94.jpg\n",
      "images\\happy\\ipsos-global-advisor-happiness-2022-opti.jpg\n",
      "images\\happy\\istock-527028804.jpg\n",
      "images\\happy\\iStock_000015424718Small.jpg\n",
      "images\\happy\\ng-hands-up-carefree-enjoying-music-standing-against-white-wall_176420-38816.jpg\n",
      "images\\happy\\people-who-are-truly-happy.png\n",
      "images\\happy\\pexels_pixabay.jpg\n",
      "images\\happy\\shiny-happy-people.jpg\n",
      "images\\happy\\smile.woman_.jpg\n",
      "images\\happy\\smiley-1635449_1280.png\n",
      "images\\happy\\Successful-year.jpg\n",
      "images\\happy\\sunset-570881_1280.jpg\n",
      "images\\happy\\traitshappypeople.jpg\n",
      "images\\happy\\U3rmkCcX_400x400.jpg\n",
      "images\\happy\\v4-460px-Make-a-Person-Happy-Step-14.jpg\n",
      "images\\happy\\what-makes-people-happy1.jpg\n",
      "images\\sad\\1184437.jpg\n",
      "images\\sad\\141203-depression-stock.jpg\n",
      "images\\sad\\171220-music.jpg\n",
      "images\\sad\\28-289800_happy-sad-face-png-sad-faces.png\n",
      "images\\sad\\29aef5ffaadeff0962806186f2d500ec-700.jpg\n",
      "images\\sad\\322233_1100-732x549.jpg\n",
      "images\\sad\\360_F_118396217_l02xTLRakFADBX5TY0CXjvDSh5BaW6y8.jpg\n",
      "images\\sad\\548165.jpg\n",
      "images\\sad\\673-6737309_face-sadness-smiley-emoticon-clip-art-drawing-of.png\n",
      "images\\sad\\98061648.jpg\n",
      "images\\sad\\all-those-people-who-are-sad-17573-1.jpg\n",
      "images\\sad\\anxiety-suddenly-feel-sad.png\n",
      "images\\sad\\Crying-Boy-Pexels-9-19.jpeg\n",
      "images\\sad\\dark-depression-mood-people-wallpaper-preview2.jpg\n",
      "images\\sad\\depression-1020x680.jpg\n",
      "images\\sad\\Depresssion-Feature.jpg\n",
      "images\\sad\\desktop-wallpaper-pencil-drawings-of-sad-faces.jpg\n",
      "images\\sad\\desktop-wallpaper-sad-love-sad-thumbnail.jpg\n",
      "images\\sad\\dZ5aCmv8izKeDWcdohG2h7.jpg\n",
      "images\\sad\\e-sad-emoji-graphic-sadness-face-vaporwave-sticker-face-purple-violet-people.png\n",
      "images\\sad\\er-symbol-sorrow-sadness-mental-disorder-unhappy-stressed-student_87946-5232.jpg\n",
      "images\\sad\\girl-447701_1280.jpg\n",
      "images\\sad\\girl-sad-face-cartoon-cute-png2.png\n",
      "images\\sad\\goodbye-to-love-paul-lovering.jpg\n",
      "images\\sad\\HD-wallpaper-sad-and-alon-alone-box-mom-people-sadness.jpg\n",
      "images\\sad\\Heart-touching-Sad-Paragraphs-For-Her-And-Him-267x300.jpg\n",
      "images\\sad\\image19.jpeg\n",
      "images\\sad\\images140.jpg\n",
      "images\\sad\\images158.jpg\n",
      "images\\sad\\images173.jpg\n",
      "images\\sad\\images175.jpg\n",
      "images\\sad\\images193.jpg\n",
      "images\\sad\\images210.jpg\n",
      "images\\sad\\images215.jpg\n",
      "images\\sad\\images228.jpg\n",
      "images\\sad\\images232.jpg\n",
      "images\\sad\\images239.jpg\n",
      "images\\sad\\images247.jpg\n",
      "images\\sad\\images258.jpg\n",
      "images\\sad\\images261.jpg\n",
      "images\\sad\\images267.jpg\n",
      "images\\sad\\images293.jpg\n",
      "images\\sad\\images30.jpg\n",
      "images\\sad\\images302.jpg\n",
      "images\\sad\\images311.jpg\n",
      "images\\sad\\images316.jpg\n",
      "images\\sad\\images32.jpg\n",
      "images\\sad\\images320.jpg\n",
      "images\\sad\\images331.jpg\n",
      "images\\sad\\images338.jpg\n",
      "images\\sad\\images352.jpg\n",
      "images\\sad\\images356.jpg\n",
      "images\\sad\\images39.jpg\n",
      "images\\sad\\images395.jpg\n",
      "images\\sad\\images396.jpg\n",
      "images\\sad\\images397.jpg\n",
      "images\\sad\\images400.jpg\n",
      "images\\sad\\images412.jpg\n",
      "images\\sad\\images429.jpg\n",
      "images\\sad\\images436.jpg\n",
      "images\\sad\\images461.jpg\n",
      "images\\sad\\images462.jpg\n",
      "images\\sad\\images479.jpg\n",
      "images\\sad\\images487.jpg\n",
      "images\\sad\\images495.jpg\n",
      "images\\sad\\images521.jpg\n",
      "images\\sad\\images532.jpg\n",
      "images\\sad\\images533.jpg\n",
      "images\\sad\\images537.jpg\n",
      "images\\sad\\images538.jpg\n",
      "images\\sad\\images550.jpg\n",
      "images\\sad\\images551.jpg\n",
      "images\\sad\\images553.jpg\n",
      "images\\sad\\images568.jpg\n",
      "images\\sad\\images573.jpg\n",
      "images\\sad\\images588.jpg\n",
      "images\\sad\\images64.jpg\n",
      "images\\sad\\images70.jpg\n",
      "images\\sad\\images87.jpg\n",
      "images\\sad\\images92.jpg\n",
      "images\\sad\\images93.jpg\n",
      "images\\sad\\man-portrait-contemplative-sad-looking-at-camera-732x549-thumbnail.jpg\n",
      "images\\sad\\man-with-head-down-300x300.jpg\n",
      "images\\sad\\ng-down-dumps-feeling-upset-displeased-standing-yellow-background_1258-58873.jpg\n",
      "images\\sad\\OT-seasonal-affective-disorder.png\n",
      "images\\sad\\sad-emoji-1024x1024-ibj29re8.png\n",
      "images\\sad\\sad-people.jpg\n",
      "images\\sad\\sad-quotes-in-english.jpg\n",
      "images\\sad\\Sad-status-for-girl.jpg\n",
      "images\\sad\\sad-status-in-hindi-image-funkylife-16-1.jpg\n",
      "images\\sad\\sad20pixabay.jpg\n",
      "images\\sad\\sadpersonas-risks-symptoms-suicide.jpg\n",
      "images\\sad\\Seasonal-Affective-Disorder.jpeg\n",
      "images\\sad\\sideview-of-sad-young-woman-wearing-denim-jacket-in-royalty-free-image-1678733541.jpg\n",
      "images\\sad\\v4-460px-Make-a-Sad-Person-Happy-Step-10.jpg\n",
      "images\\sad\\what_depression_Stocksy_txpbaa03853XyS300_Medium_1307513_Thumb-732x549.jpg\n"
     ]
    }
   ],
   "source": [
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.Dataset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 199 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_iterator = data.as_numpy_iterator()\n",
    "#batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "#for idx, img in enumerate(batch[0][:4]):\n",
    "#    ax[idx].imshow(img.astype(int))\n",
    "#    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0- happy, 1- sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaled = batch[0]/255\n",
    "#scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaled.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x, y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_iterator = data.as_numpy_iterator()\n",
    "batch = scaled_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img)\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.7)\n",
    "val_size = int(len(data)*.2)\n",
    "test_size = int(len(data)*.1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 16)        4624      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 57600)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               14745856  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,755,825\n",
      "Trainable params: 14,755,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=10, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "plt.legend(loc='upper left')\n",
    "plt.suptitle('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.suptitle('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator():\n",
    "    x, y = batch\n",
    "    yhat = model.predict(x)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precision:{pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"test\\\\happy2.jpg\"\n",
    "img = cv2.imread(path)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.image.resize(img, (256, 256))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#yhat = model.predict(np.expand_dims(resize/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if yhat>0.5, image is happy, else sad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39msave(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mimageclassifier.h5\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(os.path.join('models', 'imageclassifier.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(os.path.join('models', 'image_classifier.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhatnew = new_model.predict(np.expand_dims(resize/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhatnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Happy', 'Sad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" def predict_img(path):\n",
    "    img = cv2.imread(path)\n",
    "    resize = tf.image.resize(img, (256, 256))\n",
    "    prediction = new_model.predict(np.expand_dims(resize/255, 0))\n",
    "    if prediction>0.5:\n",
    "        return \"Happy\"\n",
    "    else: return \"Sad \"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img(img):\n",
    "    resize = tf.image.resize(img, (256, 256))\n",
    "    prediction = model.predict(np.expand_dims(resize/255, 0))\n",
    "    return \"The image is: Happy\" if prediction<0.5 else \"The image is: Sad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_img(\"test\\sad1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\lib\\site-packages\\gradio\\inputs.py:259: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\lib\\site-packages\\gradio\\inputs.py:262: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7867\n",
      "Running on public URL: https://ea499f0899ec655615.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://ea499f0899ec655615.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    }
   ],
   "source": [
    "image = gr.inputs.Image(shape=(256, 256))\n",
    "\n",
    "demo = gr.Interface(fn=predict_img, inputs=\"image\", outputs=\"text\")\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
